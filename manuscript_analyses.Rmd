---
title: "Analyses for course manuscript"
output: 
  html_document:
    theme: readable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, collapse=TRUE, eval=FALSE)
```

In this script you will apply the cleaning and analyses steps from the course to generate species richness maps and conservation assessments for your taxonomic group of interest. In step 1 you will have to define some global variables and for steps 2 (data download) and 3 (automated cleaning) you must choose between different options depending on your organism group. You can generally just copy the code, but please ***go through it step by step and make sure everything worked***, as we did during the course. The entire analysis should not take you longer than a few hours. 


In the end you will upload summary files and a short text interpreting the results using your knowledge of the group. You will then upload the results to the shared Google drive. If you encounter problems check the tutorial for the course, and if this doesn't help, ask to the other students, by sending an email to [2018_natal_biodiversity_data_course@googlegroups.com](mailto:2018_natal_biodiversity_data_course), and please reply to questions in the group when you know a solution. You'll get an invitation to join this group soon.

Before start, read all instructions below until the end. Check the questions you will have to answer and pay attention to all instructions, including the in-code comments after the #. 


# Load libraries
Make sure that all necessary libraries are installed. You might need to install the "ggalt" and "ggthemes" packages which we did not use in the course. If you need to re-install CoordinateCleaner using devtools (`install_github`), make sure to restart R after the installation.

```{r}
library(tidyverse)
library(CoordinateCleaner)
library(countrycode)
library(ConR)
library(rgbif)
library(speciesgeocodeR)
library(viridis)
library(rnaturalearth)
#install.packages(c("ggalt", "ggthemes"))
library(ggalt)
library(ggthemes)
```


# 1. Set up global operators
First, we will set some global operators to standardize the output names and to make it easy to combine data from multiple taxonomic groups. Please replace the red text with the respective settings for your group and computer.

```{r, echo=FALSE}
taxon <- "Malvaceae"
taxon_rank <- "family" #e.g. "Family", make sure to start with a capital letter
phylum <- "plants" # either "animals" or "plants"
life_form <- "terrestrial" # either "terrestrial", or "marine"
researcher <- "alex" #without special characters

# automatically creates an output folder from your taxon name
outp <- paste(taxon, "results", sep = "_")
dir.create(outp)
```



```{r, eval=FALSE}
setwd("PATH TO YOUR WORKING DIRECTORY ON YUR COMPUTER") #e.g. "C:/Users/alexander.zizka/Documents"

taxon <- "THE NAME OF YOUR TAXON" #e.g. "Malvaceae"
taxon_rank <- "THE TAXONOMIC RANK OF YOUR TAXON" #e.g. "Family", make sure to start with a capital letter
phylum <- "THE PHYLUM OF YOUR GROUP" # either "animals" or "plants"
life_form <- "THE LIFE FORM" # either "terrestrial", or "marine"
reasercher <- "YOUR FIRST NAME" #without special characters (é, ã, ç, ô, etc.)  

# automatically creates an output folder from your taxon name
outp <- paste(taxon, "results", sep = "_")

dir.create(outp)
```


# 2. Download data
As first step, download the occurrence records for your group as we did during the course. Remember to first check the taxon keys and the number of records available. You an chose to either download data for the entire Neotropics, using the polygon indicated below, or for Brazil using the country option. If there is no clear taxonomic definition for your group available from GBIF, it is best to download data on a genus by genus level. Make sure that no individual call to `occ_search()` surpasses 250,000 records. If your group has more records, please use the GBIF online portal. ***Please chose one of the three following options.***


## Option 1 - the neotropics using a polygon 
```{r, eval=FALSE}
#Use the name_suggest function to get the gbif taxon key
tax_key <- name_suggest(q = taxon, rank = taxon_rank) 

#Sometimes groups have multiple taxon keys, in this case three, so we will check how many records are available for them
lapply(tax_key$key, "occ_count")

#Here the firsrt one is relevant, check for your group!
tax_key <- tax_key$key[1]

# Download data for Neotropics
## The extent of Morrone's 2014 bioregionalization
study_a <- wicket::wkt_correct("POLYGON((-34.7 32.8, -117.2 32.8, -117.2 -55.8, -34.7 -55.8, -34.7 32.8))")

dat  <- occ_search(taxonKey = tax_key, return = "data", hasCoordinate = T,
                   geometry = study_a, limit = 250000) 
```


## Option 2 -  Brazil only
```{r, eval=FALSE}
#Use the name_suggest function to get the gbif taxon key
tax_key <- name_suggest(q = taxon, rank = taxon_rank) # fill in the correct taxonomic rank

#Sometimes groups have multiple taxon keys, in this case three, so we will check how many records are available for them
lapply(tax_key$key, "occ_count")

#Here the firsrt one is relevant, check for your group!
tax_key <- tax_key$key[1]

# count records available
occ_count(tax_key, country = "BR") 

# Download data for Brazil
dat  <- occ_search(taxonKey = tax_key, return = "data", hasCoordinate = T,
                   country = "BR", limit = 250000) 
```


## Option 3 - Genera list for the Neotropics
Use this option if you have too many species for option 1 or your group is of an unusual taxonomic rank, e.g. a tribe or a subfamily or similar.

```{r}
gen_list <- c("Bombax", "Pseudobombax") #Replace with your genera of interest

#Get taxon keys
tax_key <- lapply(gen_list, function(k){name_suggest(q = k, rank = "Genus")})
tax_key <- unlist(lapply(tax_key, "[[", "key"))

#Check the number of records per genus
unlist(lapply(tax_key, "occ_count"))

#dowload records
## The extent of Morrone's 2014 bioregionalization
study_a <- wicket::wkt_correct("POLYGON((-34.7 32.8, -117.2 32.8, -117.2 -55.8, -34.7 -55.8, -34.7 32.8))")

dat_ne  <- occ_search(taxonKey = tax_key, return = "data", hasCoordinate = T,
                      geometry = study_a, limit = 250000)
dat_ne <- lapply(dat_ne, "as.data.frame")

dat <- bind_rows(dat_ne)
```


# Automated cleaning
We will now run the automated flagging using `CoordinateCleaner`. Remember to use the test argument to chose the tests that are suitable for your group. If your group is marine, we will till run the marine test but then reverse the flags using the code below, to mark records on  land. For the seas test we will use the buffland reference to avoid flagging records in coastal areas. we will create a summary flag for each test for the paper. ***Please chose one of the following two options, depending on if your group is terrestrial or marine.***

## Option 1 - for terestrial organisms
```{r}
#convert countrycode
dat <- dat %>%
  mutate(countryCode = countrycode(dat$countryCode, origin =  'iso2c', destination = 'iso3c'))

#flag problems
dat <- data.frame(dat)
flags <- clean_coordinates(x = dat, 
                           lon = "decimalLongitude", 
                           lat = "decimalLatitude",
                           countries = "countryCode", 
                           species = "species",
                           tests = c("capitals", "centroids", "equal","gbif", "institutions",
                                    "zeros", "countries", "seas", "duplicates", "urban"),
                           seas_ref = buffland) # most test are on by default


#summary flags
suma <- summary(flags)
```


## Option 2 - for marine organisms
```{r, eval=F}
#convert countrycode
dat <- dat %>%
  mutate(countryCode = countrycode(dat$countryCode, 
                                   origin =  'iso2c', 
                                   destination = 'iso3c'))

#flag problems
dat <- data.frame(dat)
flags <- clean_coordinates(x = dat, 
                           lon = "decimalLongitude", 
                           lat = "decimalLatitude",
                          countries = "countryCode", 
                          species = "species",
                          tests = c("capitals", "centroids", 
                                    "equal","gbif", "institutions",
                                    "zeros", "seas", "duplicates", "urban"),
                          seas_ref = buffland) # most test are on by default


flags$.sea <- !flags$.sea
flags <- flags%>%
  as.data.frame()%>%
  dplyr::select(-.summary)%>%
  dplyr::select(starts_with("."))

flags$.summary <- apply(flags, 1, "all")

#summary flags
flags <- apply(flags, 2, "!")
suma <- apply(flags, 2, "sum")
```


# Metadata cleaning
We will now flag records according to the meta data, as during the course.

```{r}
# flag records without coordinates
coord_no <- !is.na(dat$decimalLongitude) | !is.na(dat$decimalLatitude)

#remove records with low coordinate precision
coord_prec <- dat$coordinateUncertaintyInMeters/1000 <= 100 | 
  is.na(dat$coordinateUncertaintyInMeters)

#remove unsuitable data sources, here you ahve to judge which ones are reliable. PLease in any case exclude "Living specimen" and "fossils"
table(dat$basisOfRecord)

coord_base <- dat$basisOfRecord == "HUMAN_OBSERVATION" | 
  dat$basisOfRecord == "OBSERVATION" |
  dat$basisOfRecord == "PRESERVED_SPECIMEN" | 
  is.na(dat$basisOfRecord)

#Individual count
ind_coun <- (dat$individualCount > 0 | is.na(dat$individualCount)) &
  (dat$individualCount < 99 | is.na(dat$individualCount)) # high counts are not a problem

# Record age
rec_age <- dat$year > 1945

# Identification
## Here you might need to add additional categories if your dataset includes additional ranks below the species level
table(dat$taxonRank) 
rec_id <- dat$taxonRank == "SPECIES" | 
  dat$taxonRank == "SUBSPECIES" |
  dat$taxonRank == "VARIETY" |
  dat$taxonRank == "FORM" |
  is.na(dat$taxonRank)

#create clean dataset
rm <- flags$.summary
if(length(coord_no) > 0) {rm <- rm & coord_no}
if(length(coord_prec) > 0) {rm <- rm & coord_prec}
if(length(coord_base) > 0) {rm <- rm & coord_base}
if(length(ind_coun) > 0) {rm <- rm & ind_coun}
if(length(rec_age) > 0) {rm <- rm & rec_age}
if(length(rec_id) > 0) {rm <- rm & rec_id}

dat_cl <-dat%>%filter(rm)

#create output and write to disk
flag_sum <- suma %>%
  t()%>%
  data.frame()%>%
  mutate(
    coordinate_missing = sum(!coord_no),
    coordinate_precision = sum(!coord_prec),
    coordinate_base = sum(!coord_base),
    individual_count = sum(!ind_coun),
    record_age = sum(!rec_age),
    record_id = sum(!rec_id),
    raw_records = nrow(dat),
    raw_taxa = length(unique(dat$species)),
    clean_records = nrow(dat_cl),
    clean_taxa = length(unique(dat_cl$species)),
    taxon = taxon,
    phylum = phylum,
    taxon_rank = taxon_rank,
    life_form = life_form,
    researcher = researcher)

write_csv(flag_sum, 
          path = file.path(outp, paste(taxon, "filtering_summary.csv", sep = "_")))


```

# Species richness
As during the course we will create species richness maps using a 100x100 km gridcells. We will generate one raster for the raw and filtered dataset respectively.

```{r}
# Define projections
wgs1984 <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
behr <- '+proj=cea +lon_0=0 +lat_ts=30 +x_0=0 +y_0=0 +datum=WGS84 +ellps=WGS84 +units=m +no_defs'

# create a equal area template in behrman projection
be <- raster(ncol = 360, nrow = 142, 
             xmn = -17367529, xmx = 17367529, 
             ymn = -6356742, ymx = 7348382,
             crs = CRS(behr))

# Raw dataset
## reproject the occurrence records
pts <- dat[, c("decimalLongitude", "decimalLatitude")]%>%
  SpatialPoints(proj4string = CRS(wgs1984))%>%
  spTransform(CRS(behr))

be <- crop(be, extent(pts))

pts <- data.frame(dat$species, coordinates(pts))

# Equal area speces richness
rw_ri <- RichnessGrid(x = pts, ras = be)

# write to disk
writeRaster(rw_ri, 
            filename = file.path(outp, paste(taxon, "species_richness_raster_raw", sep = "_")), 
            format = "ascii", 
            overwrite = TRUE)

## plot richness map
plo <- data.frame(rasterToPoints(rw_ri))%>%
  filter(layer > 0 )

world.inp  <- rnaturalearth::ne_download(scale = 110, 
                                         type = 'land', 
                                         category = 'physical',
                                         load = TRUE)

world.behr <- spTransform(world.inp, CRS(behr)) %>% fortify()

rw_plo <- ggplot()+
  geom_polygon(data = world.behr,
           aes(x = long, y = lat, group = group), fill = "transparent", color = "black")+
  geom_tile(data = plo, aes(x = x, y = y, fill = layer), alpha = 0.8)+
  scale_fill_viridis(name = "Species", direction = -1, na.value = "transparent")+
  coord_fixed()+
  ggtitle(taxon)+
  theme_map()
 
ggsave(rw_plo, 
       filename = file.path(outp, paste(taxon, "species_richness_map_raw.tiff", sep = "_")))


# clean dataset
## reproject the occurrence records
pts <- dat_cl[, c("decimalLongitude", "decimalLatitude")]%>%
  SpatialPoints(proj4string = CRS(wgs1984))%>%
  spTransform(behr)

be <- crop(be, extent(pts))

pts <- data.frame(dat_cl$species, coordinates(pts))

# Equal area speces richness
cl_ri <- RichnessGrid(x = pts, ras = be)

# write to disk
writeRaster(cl_ri, 
            filename = file.path(outp, paste(taxon, "species_richness_raster_filtered", sep = "_")), 
            format = "ascii", 
            overwrite = TRUE)

## plot richness map
plo <- data.frame(rasterToPoints(cl_ri))
plo[,c(1,2)] <- coordinates(spTransform(SpatialPoints(plo[, c("x", "y")], proj4string = CRS(behr)), CRS(wgs1984)))
world.inp  <- map_data("world")


cl_plo <- ggplot()+
  geom_map(data = world.inp, map = world.inp, aes(x = long, y = lat, map_id = region), fill = "grey80")+
  coord_proj(behr)+
  geom_tile(data = plo, aes(x = x, y = y, fill = layer))+
  scale_fill_viridis(name = "Species", direction = -1, na.value = "transparent")+
  ggtitle(taxon)+
  theme_map()

ggsave(cl_plo, filename = file.path(outp, paste(taxon, "species_richness_map_filtered.tiff", sep = "_")))
```

# Conservation assessment
Now we will do the conservation assessment for each species based on the raw and the cleaned dataset, as during the course.

```{r}
# Format input data
rw_in <- dat%>%
  dplyr::select(ddlat = decimalLatitude,
                ddlon = decimalLongitude, 
                tax = species)

cl_in <- dat_cl%>%
  dplyr::select(ddlat = decimalLatitude,
                ddlon = decimalLongitude, 
                tax = species)


# Preliminary assessment
rw_ass <- IUCN.eval(rw_in)
names(rw_ass) <- paste("raw_", names(rw_ass), sep = "")
cl_ass <- IUCN.eval(cl_in)
names(cl_ass) <- paste("filtered_", names(cl_ass), sep = "")

# prepare output
ass <- full_join(rw_ass, cl_ass, by = c("raw_taxa" = "filtered_taxa"))

# Write summary to disk
write_csv(ass, path = paste(outp, "/", taxon, "_conservation_assessment.csv", sep = ""))

# summary table with species number per category
sum_rw <- ass%>%
  group_by(raw_Category_CriteriaB)%>%
  summarize(count = n())

sum_cl <- ass%>%
  group_by(filtered_Category_CriteriaB)%>%
  summarize(count = n())

sum_ass <- full_join(sum_rw, 
                     sum_cl, 
                     by = c("raw_Category_CriteriaB" = "filtered_Category_CriteriaB"))

write_csv(sum_ass, 
          path = paste(outp, "/", taxon, "_conservation_assessment_Summary.csv", sep = ""))

```


# Check results
Now open your working directory in the Windows explorer (or Finder for Mac users) and check the output. Make sure the following files are in the `taxon_result` sub folder of your working directory:

* a summary table of the cleaning steps ("taxon_cleaning_summary.csv")
* a species richness map based on the raw data ("taxon_species_richness_map_raw.tiff")
* a species richness map of the filtered data ("taxon_species_richness_map_filtered.tiff")
* a raster file of the species richness based on the raw data ("taxon_species_richness_raster_raw.asc")
* a raster file of the species richness based on the filter data ("taxon_species_richness_raster_filtered.asc")
* a table with the conservation status, including data from the raw and filtered data ("taxon__conservation_assessment.csv")
* a table summarizing the number of species in each conservation category ("taxon__conservation_assessment_summary.csv")


# Interpretation of the results
Write two paragraphs (not more!) using your knowledge of your group to judge the results. It can be in English or Portuguese (it is important to be well written. Ask some colleagues to read it before send us the final version)Make sure to address the following questions:

* Does the number of flagged records seem reasonable?
* Was there any filtering issue particularly striking in your group (e.g too many records excluded or too few)? What could be the reason for those?
* Based on the knowledge of your group is the raw or filtered richness maps more accurate? Why?
* Based on the knowledge of your group is the raw or filtered conservation assessment more useful? Why?
* Of those species with a conservation assessment in both datasets, which one was more accurate in your opinion?
* Compare your conservation assessment to the assessment from www.iucn.org (for animals) and https://www.bgci.org/threat_search.php (for plants). If the group you chose has too many species compare the summary numbers, i.e. how many species are there in each threat category in our assessment vs. the reference once.
* How many species in your group are in your assessment in total and for how many is an assessment available from iucn or threat base?

# Finally

Once you are sure all result files are OK and you wrote your interpretation (two paragraphs of a well written text in Portuguese or English), upload your taxon_results folder and a word document with the two paragraphs on your group named "taxon_interpretation_yourfirstname" to this Google drive folder: https://drive.google.com/drive/folders/1II1XEXTXo91CRgoJrwGeP9wNbv97-Fvq?usp=sharing.

Well done! :-)






